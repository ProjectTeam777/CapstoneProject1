# CapstoneProject1
Import Libraries
import yfinance as yf import quandl import talib import backtrader #cerebro import pandas as pd
import Scikit-learn
import scipy
import matplotlib.pyplot
import numpy as np
pip install vaderSentiment
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

**Step-1: Gathering and Cleaning Historical Data**
#Libraries such as yfinance, quandl
#Gather Data stock_data = yf.download('Stock_Ticker', start='2014-01-01', end='2024-01-01')

# Check if the data is empty
if stock_data.empty:
raise ValueError("Error: No data found for the specified ticker and date range."). #Clean and Fill Missing Data stock_data.fillna(method='ffill', inplace=True)
#Drop any NaN rows in the data
stock_data.dropna(inplace=True)
#Data validation
def validate_data(stock_data):
if stock_data.isnull().sum().sum() > 0:
print("Warning: Missing data found.")
if not pd.api.types.is_datetime64_any_dtype(stock_data.index):
stock_data.index = pd.to_datetime(stock_data.index)
validate_data(stock_data)

**Step-2: Technical and Fundamental Analysis**
#Libraries such as TA-Lib
def calculate_technical_indicators(df): # Implement technical indicators # (e.g., SMA, EMA, RSI, MACD, Bollinger Bands, ADX, ATR) pass
#include volatility data
def get_vix_data(start_date, end_date): vix_data = yf.download('^VIX', start=start_date, end=end_date) return vix_data[['Close']]
#Download options data and include Put/Call parity ratio for the analysis
def get_options_data(stock_symbol, expiry_date):
options_data = quandl.get_table('OPT/CHAIN', symbol=stock_symbol, expiration=expiry_date)
return options_data[['strike', 'option_type', 'implied_volatility', 'open_interest']]
def calculate_put_call_ratio(options_data):
puts = options_data[options_data['option_type'] == 'put']
calls = options_data[options_data['option_type'] == 'call']
put_call_ratio = puts['open_interest'].sum() / calls['open_interest'].sum()
return put_call_ratio

**Step-3: Strategy Development and Backtesting**
#Libraries such as Cerebro #Running Backtest
def run_backtest(stock_data): cerebro = bt.Cerebro() cerebro.addstrategy(SwingTradingStrategy) data = bt.feeds.PandasData(dataname=stock_data) cerebro.adddata(data) cerebro.run() cerebro.plot()

**Step-4: Sentiment Analysis**
# Libraries such as TextBlob, TwitterAPI, NewsAPI, RedditAPI, Tweepy, Praw
def fetch_sentiment_data(symbols, start_date, end_date): pass
def analyze_sentiment(sentiment_data): pass
#Additional advance sentiment analysis tools for model performance enhancement
def analyze_sentiment(text_data):
analyzer = SentimentIntensityAnalyzer()
sentiment_scores = [analyzer.polarity_scores(text)['compound'] for text in text_data]
return sentiment_scores

**Step-5: Risk Management (Stop-Loss)**
# 5% stop loss(Will further change or update based on our model design) def risk_management(data): stop_loss = 0.05 for i in range(len(data)): if data['Close'][i] < (data['Close'].iloc[i-1] * (1 - stop_loss)): data['Signals'][i] = -1 # Sell if stop loss is hit return data
OR
#ATR-based dynamic stop-loss to adjust with volatility instead of a fixed 5% stop-loss. Will decide stop loss method later based on model design.
def risk_management(data, atr_period=15):
data['ATR'] = talib.ATR(data['High'], data['Low'], data['Close'], timeperiod=atr_period)
for i in range(len(data)):
stop_loss = 2 * data['ATR'][i] # Dynamic stop-loss based on volatility
if data['Close'][i] < (data['Close'].iloc[i-1] - stop_loss):
data['Signals'][i] = -1 # Sell if stop-loss is hit
return data

**Step-6: Performance Evaluation**
def calculate_performance_metrics(stock_data): returns = stock_data['Close'].pct_change() sharpe_ratio = (returns.mean() / returns.std()) * np.sqrt(252)
max_drawdown = (stock_data['Close'].cummax() - stock_data['Close']).max() return sharpe_ratio, max_drawdown
#calculation of different performance ratios for model calibrations and enhancements
def calculate_performance_metrics(stock_data, confidence_level=0.95):
Calculate returns
returns = stock_data['Close'].pct_change()
# Sharpe Ratio
sharpe_ratio = (returns.mean() / returns.std()) * np.sqrt(252)
# Sortino Ratio (only penalize downside risk)
sortino_ratio = (returns.mean() / returns[returns < 0].std()) * np.sqrt(252)
# Calmar Ratio (return divided by maximum drawdown)
calmar_ratio = returns.mean() / (stock_data['Close'].cummax() - stock_data['Close']).max()
return sharpe_ratio, sortino_ratio, calmar_ratio
